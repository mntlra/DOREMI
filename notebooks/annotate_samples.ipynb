{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6c30d7",
   "metadata": {},
   "source": [
    "# Annotate Sample\n",
    "\n",
    "This notebook provides a user-friendly interface to visualize the documents and triples to be annotated. Annotations must be stored in a CSV file, which is then converted in a JSON file to be merged with the training file of the previous DOREMI iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018260cd-cce3-463c-9865-346c5bdca06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### READ SAMPLE #####\n",
    "filename = \"sample_agreement_logsum_iter1\"\n",
    "dataset = \"docred\" # Dataset used for the iterations (either docred or redocred)\n",
    "sample_path = f\"../data/{dataset}/{filename}.json\"\n",
    "sample = json.load(open(sample_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary with the sample\n",
    "title2sample = {}\n",
    "for s in sample:\n",
    "    title2sample[s[\"title\"]] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9066a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload models' predictions\n",
    "# Edit with the directory containing the checkpoints for the considered iteration\n",
    "predicitions_directory \"pretrain_redocred\"\n",
    "models = [\"CNN3\", \"ContextAware\", \"LSTM\", \"BiLSTM\", \"BERT\"]\n",
    "title2preds = {}\n",
    "for m in models:\n",
    "    title2preds[m] = {}\n",
    "    predictions = json.load(open(f\"../data/checkpoints/{m}/{predicitions_directory}/train_distant_results.json\"))\n",
    "    for p in predictions:\n",
    "        if p[\"title\"] in title2sample.keys():\n",
    "            if str(p[\"h_idx\"]) in title2sample[p[\"title\"]][\"old2new\"].keys() and str(p[\"t_idx\"]) in title2sample[p[\"title\"]][\"old2new\"].keys():\n",
    "                h_idx = title2sample[p[\"title\"]][\"old2new\"][str(p[\"h_idx\"])]\n",
    "                t_idx = title2sample[p[\"title\"]][\"old2new\"][str(p[\"t_idx\"])]\n",
    "                if p[\"title\"] in title2preds.keys():\n",
    "                    if (h_idx,t_idx) in title2preds[m][p[\"title\"]].keys():\n",
    "                        title2preds[m][p[\"title\"]][(h_idx, t_idx)].append({'r': p[\"r\"], 'score': p[\"score\"]})\n",
    "                    else:\n",
    "                        title2preds[m][p[\"title\"]][(h_idx, t_idx)] = [{'r': p[\"r\"], 'score': p[\"score\"]}]\n",
    "                else:\n",
    "                    title2preds[m][p[\"title\"]] = {}\n",
    "                    title2preds[m][p[\"title\"]][(h_idx, t_idx)] = [{'r': p[\"r\"], 'score': p[\"score\"]}]  \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the csv file storing the annotations\n",
    "# RUN ONLY THE FIRST TIME -- OTHERWISE IT ERASES ALL ANNOTATIONS\n",
    "csv_file = f\"{filename}_annotations.csv\"\n",
    "with open(f\"annotations/{csv_file}\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, delimiter=\";\")\n",
    "    writer.writerow([\"Title\", \"h_idx\", \"t_idx\", \"rels\"])\n",
    "\n",
    "# Storing the triples to be annotated\n",
    "for d in sample:\n",
    "    for h_idx, h in enumerate(d[\"vertexSet\"]):\n",
    "        for t_idx, t in enumerate(d[\"vertexSet\"]):\n",
    "            if h != t and [h_idx,t_idx] in d[\"include_pairs\"]:\n",
    "                with open(f\"annotations/{csv_file}\", mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                    writer = csv.writer(f, delimiter=\";\")\n",
    "                    writer.writerow([d[\"title\"], h_idx, t_idx, []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an index to track the current position\n",
    "current_index = 0\n",
    "\n",
    "# Create a button widget\n",
    "next_button = widgets.Button(description=\"Next\")\n",
    "back_button = widgets.Button(description=\"Back\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Function to update the display\n",
    "def update_output():\n",
    "    with output:\n",
    "        clear_output(wait=True)  # Clear the previous output\n",
    "        # Get the next item from the iterator\n",
    "        d = sample[current_index]\n",
    "        title = d[\"title\"]\n",
    "        print(f\"DOCUMENT: {title}\")\n",
    "        for s in d[\"sents\"]:\n",
    "            print(\" \".join([tok for tok in s]))\n",
    "        print()\n",
    "        for h_idx, h in enumerate(d[\"vertexSet\"]):\n",
    "            for t_idx, t in enumerate(d[\"vertexSet\"]):\n",
    "                if h != t and [h_idx,t_idx] in d[\"include_pairs\"]:\n",
    "                    h_name = {h[0][\"name\"]}\n",
    "                    t_name = {t[0][\"name\"]}\n",
    "                    print(f\"Pair to consider: ({h_idx}) {h_name}; ({t_idx})) {t_name}\")\n",
    "                    for m in models:\n",
    "                        if title not in title2preds[m].keys():\n",
    "                            print(f\"\\t{m}: []\")\n",
    "                        elif (h_idx,t_idx) not in title2preds[m][title].keys():\n",
    "                            print(f\"\\t{m}: []\")\n",
    "                        else:\n",
    "                            print(f\"\\t{m}: {title2preds[m][title][(h_idx,t_idx)]}\")\n",
    "\n",
    "# Function to handle \"Next\" button click\n",
    "def on_next_button_clicked(b):\n",
    "    global current_index\n",
    "    if current_index < len(sample) - 1:  # Check if we can move forward\n",
    "        current_index += 1\n",
    "        update_output()\n",
    "    if current_index == len(sample) - 1:  # Disable \"Next\" if at the end\n",
    "        next_button.disabled = True\n",
    "    back_button.disabled = False  # Enable \"Back\"\n",
    "\n",
    "# Function to handle \"Back\" button click\n",
    "def on_back_button_clicked(b):\n",
    "    global current_index\n",
    "    if current_index > 0:  # Check if we can move backward\n",
    "        current_index -= 1\n",
    "        update_output()\n",
    "    if current_index == 0:  # Disable \"Back\" if at the start\n",
    "        back_button.disabled = True\n",
    "    next_button.disabled = False  # Enable \"Next\"\n",
    "\n",
    "# Attach button click events\n",
    "next_button.on_click(on_next_button_clicked)\n",
    "back_button.on_click(on_back_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e5a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize buttons and display the first item\n",
    "back_button.disabled = True  # Start with \"Back\" disabled\n",
    "update_output()\n",
    "\n",
    "# Display the buttons and output\n",
    "display(widgets.HBox([back_button, next_button]), output)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d1eb5",
   "metadata": {},
   "source": [
    "# Creation of the annotated sample JSON file\n",
    "\n",
    "This section generates a JSON file containing the annotated sample. Such a file will be merge to the training file to produce the finetuning dataset for the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e81315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample json\n",
    "csv_file = f\"{filename}_annotations.csv\"\n",
    "annotations = pd.read_csv(f\"annotations/{csv_file}\", sep=\";\")\n",
    "annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d21386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load relations information\n",
    "rel_info = json.load(open(\"../data/docred/rel_info.json\", \"r\"))\n",
    "relations = [\"NA\"]\n",
    "relations.extend([f\"{k}\" for k in rel_info.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bba71-c214-4b76-a095-89836bd43bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the positive examples\n",
    "title2labels = {}\n",
    "num_rels = 0\n",
    "for ix, col in annotations.iterrows():\n",
    "    list_rels = col[\"rels\"].strip(\"[]\").split(\",\")\n",
    "    print(f\"Number of relations annotated: {len(list_rels)}; {list_rels}\")\n",
    "    if len(list_rels) > 1:\n",
    "        for rel in list_rels:\n",
    "            if rel not in relations:\n",
    "                title = col[\"Title\"]\n",
    "                raise ValueError(f\"Relation {rel} of document {title} not in predefined list of relations\")\n",
    "            num_rels += 1\n",
    "            try:\n",
    "                title2labels[col[\"Title\"]].append({\"h\": col[\"h_idx\"], \"t\": col[\"t_idx\"], \"r\": rel, \"evidence\": []})\n",
    "            except KeyError:\n",
    "                title2labels[col[\"Title\"]] = [{\"h\": col[\"h_idx\"], \"t\": col[\"t_idx\"], \"r\": rel, \"evidence\": []}]\n",
    "    elif list_rels[0] != \"\":\n",
    "        if list_rels[0] not in relations:\n",
    "            title = col[\"Title\"]\n",
    "            raise ValueError(f\"Relation {list_rels[0]} of document {title} not in predefined list of relations\")\n",
    "        num_rels += 1\n",
    "        try:\n",
    "            title2labels[col[\"Title\"]].append({\"h\": col[\"h_idx\"], \"t\": col[\"t_idx\"], \"r\": list_rels[0], \"evidence\": []})\n",
    "        except KeyError:\n",
    "            title2labels[col[\"Title\"]] = [{\"h\": col[\"h_idx\"], \"t\": col[\"t_idx\"], \"r\": list_rels[0], \"evidence\": []}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of positive examples in the sample\n",
    "num_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the JSON file\n",
    "for d in sample:\n",
    "    try:\n",
    "        d[\"labels\"] = title2labels[d[\"title\"]]\n",
    "    except KeyError:\n",
    "        title = d[\"title\"]\n",
    "        print(f\"Only negative examples for {title}\")\n",
    "        d[\"labels\"] = []\n",
    "    \n",
    "json.dump(sample, open(f\"annotations/ANNOTATED_{filename}.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb7e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
